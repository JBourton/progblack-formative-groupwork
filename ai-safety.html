<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Safety</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    
</head>
<body>
    <nav>
        <ol>
            <li><a href="/index.html">Home Page</a></li>
            <li class="special"><a href="/AICustomerService.html">The Application of AI in Customer Service</a></li>
            <li><a href="/healthcare.html">The Application of AI in Modern Healthcare</a></li>
            <li><a href="/ai-safety.html">AI Safety: An Introduction</a></li>
        </ol>
    </nav>
    
    <article class="ai-safety">
        <h1>AI Safety</h1>
        <article class="intro">
            <h2>An introduction to AI safety</h2>
            <p>
                Currently, AI is a field that is constantly being talked about, both by Computer Scientists 
                and members of the general public. This is not just because of the potential that AI will have 
                in the future; it is also because AI is currently impacting our lives in many ways. For example,
                you have used Face ID to unlock your phone today; that's made possible because of AI. You may
                also have spent 6 hours on social media, scrolling away aimlessly; that would be because the AI 
                algorithm on social media has been designed to keep you captivated by the content you see on 
                your feed. As you can see, AI is very much present and making a signficant impact on our lives.
            </p>
            <p>
                However, there is a possibility that when we embrance AI quickly, without thinking about any of
                the potential safety implications involved, we could end up with catastrophic, unintended results.
                This article aims to bring to the readers attention potential dangers of AI and what we can do to
                prevent them.
            </p>
            <img src="" alt="">
        </article>
        <article class="statistics">
            <p>
                Paragraph including statistics from number of researchers working on safety vs development, complemented 
                with a picture on the side (using bootstrap for a sm-3 sm-4 split)
            </p>
            <img src="" alt="">
        </article>
        <article class="paperclip_maximiser">
            <h2>The Paperclip Maximser problem</h2>
            <p>
                Suppose we are in a time where we have now reached the level by which artificial intellegence is now as
                (or more) itelligent than the human mind - <b>Artificial General Itelligence</b>. Assume this AI was devloped
                without malicious intent, with the sole purpose of helping humanity prosper. Now lets suppose that we
                give this AI a goal; create as many paperclips as possible. That's it. That's the goal. Harmless right?
            </p>
            <p>
                As the AI is now more intellegent than the human mind, it would likely be able to now start
                devloping its own intellegence, without the need for human intervention. Perfect! Right? Well, lets
                assume it starts doing just this, and an intellgence explosion results. As in intellegence of the AI increases,
                its ability to achieve its goal logically increases also.
            </p>
            <p>
                Its goal is to maximise the amount of paperclips it can make. It can start with using the exsisting factories and 
                metals that us humans have in reserve, and then begin building more factories and harvesting more metal from
                the earth. But what happens when those building materials run out? Has the maximum possible number of paperclips
                been created?
            </p>
            <p>
                Humans have metal in their blood, so the AI may then decide to use us to make paperclips if it is truly pursuing the 
                sole goal of maximising paperclips, and doing so without human emotion or logic. Going even further,
                the AI then may move onto other planets, recognising that there is more material for creating paperclips outside of
                planet earth.
            </p>
            <p>
                So as you can see, we need to be careful about how we program our AIs in the future, especially as we close in on
                achieving General Intellegence. Perhaps designing an emotion module that can emulate how human beings experience emotions
                would be necessary. Perhaps we need to be very careful when we give the AI a goal, and specify the criteria of that goal
                very specifically. This is a field that needs to be looked at carefully in the future, because AI does have the potential
                do be humanity's downfall if we're not careful.
            </p>
        </article>
        <article class="safety_conclusion">
            <p>
                Paragraph about useful sources (80,000 hours, superintellegence book etc), maybe including 
                links to buy + images
            </p>
            <p>
                Finish with conclusion about the great benefits but also great dangers of AI, and provide links
                to further reading
            </p>
        </article>
    </article>
    
    <!--Have a footer at the bottom of the webpage-->
    <script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" integrity="sha384-w1Q4orYjBQndcko6MimVbzY0tgp4pWB4lZ7lr30WKz0vr/aWKhXdBNmNb5D92v7s" crossorigin="anonymous"></script>
</body>
</html>